<!DOCTYPE html>
<html lang="en">
  <head>
    <title>GNNs for HRI
    </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <!-- <link rel="icon" type="image/png" href="../img/favicon/rocket-solid.png"> -->
    <script src="https://kit.fontawesome.com/55d924b99d.js" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;1,300;1,400&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../css/pages.css">
  </head>
  <body>
    <div class="global-container">
      <input type="checkbox" id="menu-icon">
      <label for="menu-icon"><i class="fas fa-bars"></i></label>
      <header class="main-header">
        <h1 class="main-header__title">gnns4hri - Graph Neural Networks for Human-Robot Interaction</h1>
      </header>
      <aside class="main-aside">
        <h1 class="main-aside__title"><a href="../index.html">gnns4hri projects</a></h1>
        <div class="main-aside__nav-filter">
          <input type="text" id="filter" onkeyup="myFilter()" placeholder="Search for projects...">
        </div>
        <nav class="main-nav">
          <ul class="main-menu" id="menu">
            <li class="main-menu__item"><a href="./sonata.html">SONATA</a></li>
            <li class="main-menu__item"><a href="./sngnn1d.html">SNGNN1D</a></li>
            <li class="main-menu__item--active"><a href="#">SNGNN2D</a>
              <ul class="main-menu__submenu">
                <li class="submenu__item"><a href="#motivation">Motivation and aims</a></li>
                <li class="submenu__item"><a href="#dataset">Dataset generation</a></li>
                <li class="submenu__item"><a href="#test">Testing the cost map with an A* planner</a></li>
              </ul>
            </li>
            <li class="main-menu__item"><a href="./datasets.html">Datasets</a></li>
          </ul>
        </nav>
      </aside>
      <main class="main-content">
        <h1>Cost map for social navigation generated with a GNN</h1>

        <p>The project <b>SNGNN2D</b> pursuits to generate a 2D cost map that can be used for social navigation. The model is trained with a dataset of 2D images bootstrapped from 1D features. For doing that, we have made use of the model developed in SNGNN1D project as detailed in the <a href="#test">dataset section</a>. Additionally, we have used an A* planner to evaluate the efficiency and social compliance of the cost map (see <a href="#test">section</a>).
        <p>
        <br/>
  
        <a href="https://github.com/gnns4hri/graph2image">GitHub repository</a>.
  
        
        
        <section class="main-section">
          <h2 class="main-section__title"><a name="motivation">Motivation and aims</a></h2>
          <div class="main-section__content">
            <p>
              This project aims to provide a model for robot disruption in human comfortability that can efficiently generate two-dimensional cost maps for HAN considering interactions, an area that has been overlooked until recently.
              The <b>contributions</b> of the project are two-fold: <b>a)</b> a technique to bootstrap two-dimensional datasets from one-dimensional datasets; and <b>b)</b> <b>SNGNN-2D</b>, an architecture that combines Graph Neural Networks (GNN) and Convolutional Neural Networks (CNN) to generate two dimensional cost maps based on the robot's knowledge.
            </p>
            <p>
              After training, the resulting ML architecture is able to efficiently generate cost maps that can be used as a cost function for Human-Aware Navigation.            
            </p>
          </div>
        </section>

        <section class="main-section">
          <h2 class="main-section__title"><a name="dataset">Dataset generation</a></h2>
          <div class="main-section__content">
            <p>
              The acquisition of two-dimensional cost or disruption maps to create datasets for learning purposes generates a number of challenges. It also requires a significant commitment in comparison to their scalar value counterparts. A factor to consider is that the precision of the answer is dependent on the subjects' capability to represent the situation and their preferences graphically. Their inclination and motivation to stay engaged in the task is an additional challenge. 
            </p>
            <p>
              From an ML perspective, when factoring in an approximately equal time commitment and effort when generating answers, providing a single scalar for each scenario would yield answers for a higher number of scenarios. This would in turn generate a higher variability in the input scenarios that would make the model less prone to overfitting.
            </p>

            <figure>
              <img src="../images/sngnn2d/dataset1.png" alt="screenshot of the SocNav1 tool" style="width: 640px" />
              <figcaption>
              <b>Fig. 1:</b> SNGNN-1D  can  be  used  to  estimate  the  disruption  caused  by the robot given a particular scenario.
              </figcaption>
            </figure>

            <figure>
              <img src="../images/sngnn2d/dataset2.png" alt="screenshot of the SocNav1 tool" style="width: 640px" />
              <figcaption>
              <b>Fig. 2:</b> The  expected  2D  outputs  are  generated  performing  multiplequeries to SNGNN-1D, shifting the scenario around the robot.
              </figcaption>
            </figure>

            <p>
              A dataset containing scalars as output data cannot directly be used to train a model which provides two dimensional output, so the approach followed in this case is to use a model which provides one-dimensional value estimations (SNGNN-1D) and sample its output shifting the robot's position, bootstrapping this way a two-dimensional dataset. The process of sampling is depicted in Fig.1 and 2. For each scenario in the bootstrapped dataset a matrix of 73x73 samples is generated. A total of 37131 scenarios were randomly generated following the same strategy of SocNav1. The dataset split for training, development and test is of 31191, 2970 and 2970 scenarios, respectively.
            </p>
          </div>
        </section>

        <section class="main-section">
          <h2 class="main-section__title"><a name="test">Testing the cost map with an A* planner</a></h2>
          <div class="main-section__content">
            <p>
            As most researchers working on human-aware navigation, we used to handcraft the proxemics models our robots used for navigation.
            
            </p>
          </div>
        </section>
      
      </main>
    </div>
  </body>
  <script src="../js/index.js"></script>
</html>
